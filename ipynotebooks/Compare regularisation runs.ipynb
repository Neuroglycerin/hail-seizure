{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import numpy as np\n",
    "import operator\n",
    "import re\n",
    "import pandas as pd\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import holoviews as hv\n",
    "# Add markersize option for hv.Curve\n",
    "#hv.plotting.mpl.CurvePlot.style_opts += [u'markersize']\n",
    "options = hv.Store.options(backend='matplotlib')\n",
    "options.Curve.groups['style'].allowed_keywords += ['markersize']\n",
    "# Add holoviews notebook magic\n",
    "hv.notebook_extension('matplotlib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "subject_names = ('all', 'Dog_1', 'Dog_2', 'Dog_3', 'Dog_4', 'Dog_5', 'Patient_1', 'Patient_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csvfnm = 'regularisation_runs/AUC_scores.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the CSV with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df1 = pd.read_csv(csvfnm, sep='\\t', header=0)\n",
    "# Drop any duplicated rows from repeated runs of the same thing\n",
    "#df = df.drop_duplicates(inplace=True)\n",
    "df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to parse the RUN_NAME column to extract the features which couldn't go into the CSV file as their own columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# We need to parse the RUN_NAME column to extract the features which couldn't go into the CSV file as their own columns.\n",
    "extra_columns = df1.RUN_NAME.str.split('_').tolist()\n",
    "\n",
    "#  Splitting on underscores gets out all the fields except the regularisation entry.\n",
    "# We need to split this on the equals sign, and check that the first part is always the same!\n",
    "field_name = None\n",
    "for index, row in enumerate(extra_columns):\n",
    "    this_field_name, param_value = row[1].split('=')\n",
    "    if field_name is None:\n",
    "        field_name = this_field_name\n",
    "    elif field_name is not this_field_name:\n",
    "        raise(ValueError('fieldname mismatch'))\n",
    "    extra_columns[index][1] = float(param_value)\n",
    "\n",
    "for index, row in enumerate(extra_columns):\n",
    "    extra_columns[index][4] = int(row[4])\n",
    "\n",
    "df2 = pd.DataFrame(extra_columns,\n",
    "                   columns = ['classifier_name', field_name, 'modtyp', 'featureset', 'n_splits'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "len(extra_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "extra_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = pd.concat([df1, df2], axis=1, join_axes=[df1.index])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%opts Scatter plot[logx=True] Curve plot[logx=True]\n",
    "\n",
    "fwible = [(\n",
    "            (subject_name, clf_name, modtyp, featureset, n_splits),\n",
    "            hv.Curve(df[\n",
    "                        (df['classifier_name']==clf_name) &\n",
    "                        (df['modtyp']==modtyp) &\n",
    "                        (df['featureset']==featureset) &\n",
    "                        (df['n_splits']==n_splits)\n",
    "                     ][['C', subject_name]].sort_values(by='C').values, kdims=['C'], vdims=['AUROC'])\n",
    "          )\n",
    "          for (subject_name, clf_name, modtyp, featureset, n_splits) in itertools.product(\n",
    "            subject_names,\n",
    "            ['LR', 'SVC'],  # df['classifier_name'].unique(),\n",
    "            ['raw','ica'],  # df['modtyp'].unique(),\n",
    "            df['featureset'].unique(),\n",
    "            df['n_splits'].unique()\n",
    "            )\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "hvm = hv.HoloMap(fwible, kdims=('subject_name', 'classifier_name', 'modtyp', 'featureset', 'n_splits'))\n",
    "hvm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%output size=200\n",
    "%%opts Curve (marker='o', markersize=10, color=Palette('Set1'))\n",
    "%%opts NdOverlay [legend_position='bottom_left']\n",
    "hvm.overlay('subject_name')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%output size=120\n",
    "hvm.overlay('classifier_name').layout('modtyp').cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%%output size=120\n",
    "hvm.overlay('n_splits').layout('modtyp').cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%output size=200\n",
    "hvm.overlay('modtyp').layout('classifier_name').cols(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%output size=200\n",
    "hvm.overlay('featureset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%%output size=120\n",
    "hvm.overlay(['n_splits', 'modtyp']).layout('featureset').cols(2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
