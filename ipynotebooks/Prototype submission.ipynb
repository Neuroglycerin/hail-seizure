{
 "metadata": {
  "name": "",
  "signature": "sha256:81d47de68f1c69d9ec53f373dd4e5e298ed2f126f6cda1f559e113a4d6aedecf"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "plt.rcParams['figure.figsize'] = 6, 4.5\n",
      "plt.rcParams['axes.grid'] = True\n",
      "plt.gray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x7f25a302a080>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The aim of this notebook is to make a submission for this competition as quickly as possible.\n",
      "Just want to get something in.\n",
      "\n",
      "# Loading the data\n",
      "\n",
      "Getting all the filenames for Dog_1 ready, going to do the analysis on this first, then iterate over the rest after that."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd .."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/repositories/hail-seizure\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import train\n",
      "import json\n",
      "import imp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, have to load the settings from the json file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "settings = json.load(open('SETTINGS.json', 'r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "settings.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 6,
       "text": [
        "dict_keys(['RAW_DATA_DIRS', 'SUBJECTS', 'MODEL_PATH', 'FEATURES', 'SUBMISSION_PATH', 'DATA_TYPES', 'VERSION', 'TEST_DATA_PATH', 'TRAIN_DATA_PATH'])"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = train.get_data(settings['FEATURES'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Doing this we get a dictionary of dictionarys:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "dict"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "dict_keys(['raw_feat_var_', 'raw_feat_pib_', 'raw_feat_corrcoef_', 'raw_feat_cov_', 'raw_feat_xcorr_'])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['raw_feat_var_'].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "dict_keys(['Patient_2', 'Dog_3', 'Patient_1', 'Dog_1', 'Dog_4', 'Dog_2', 'Dog_5'])"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['raw_feat_var_']['Patient_2'].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "dict_keys(['interictal', 'preictal', 'test'])"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['raw_feat_var_']['Patient_2']['interictal'].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "dict_keys(['Patient_2_interictal_segment_0034.mat', 'Patient_2_interictal_segment_0013.mat', 'Patient_2_interictal_segment_0016.mat', 'Patient_2_interictal_segment_0040.mat', 'Patient_2_interictal_segment_0007.mat', 'Patient_2_interictal_segment_0039.mat', 'Patient_2_interictal_segment_0012.mat', 'Patient_2_interictal_segment_0033.mat', 'Patient_2_interictal_segment_0035.mat', 'Patient_2_interictal_segment_0006.mat', 'Patient_2_interictal_segment_0020.mat', 'Patient_2_interictal_segment_0015.mat', 'Patient_2_interictal_segment_0028.mat', 'Patient_2_interictal_segment_0003.mat', 'Patient_2_interictal_segment_0008.mat', 'Patient_2_interictal_segment_0014.mat', 'Patient_2_interictal_segment_0002.mat', 'Patient_2_interictal_segment_0022.mat', 'Patient_2_interictal_segment_0005.mat', 'Patient_2_interictal_segment_0029.mat', 'Patient_2_interictal_segment_0032.mat', 'Patient_2_interictal_segment_0025.mat', 'Patient_2_interictal_segment_0037.mat', 'Patient_2_interictal_segment_0036.mat', 'Patient_2_interictal_segment_0009.mat', 'Patient_2_interictal_segment_0019.mat', 'Patient_2_interictal_segment_0041.mat', 'Patient_2_interictal_segment_0011.mat', 'Patient_2_interictal_segment_0027.mat', 'Patient_2_interictal_segment_0023.mat', 'Patient_2_interictal_segment_0010.mat', 'Patient_2_interictal_segment_0042.mat', 'Patient_2_interictal_segment_0004.mat', 'Patient_2_interictal_segment_0030.mat', 'Patient_2_interictal_segment_0018.mat', 'Patient_2_interictal_segment_0026.mat', 'Patient_2_interictal_segment_0038.mat', 'Patient_2_interictal_segment_0001.mat', 'Patient_2_interictal_segment_0021.mat', 'Patient_2_interictal_segment_0031.mat', 'Patient_2_interictal_segment_0024.mat', 'Patient_2_interictal_segment_0017.mat'])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It's dictionaries __all the way down__.\n",
      "\n",
      "Until you get to the feature vectors, obviously:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['raw_feat_var_']['Patient_2']['interictal']['Patient_2_interictal_segment_0034.mat']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([[ 27997.01668904],\n",
        "       [ 35989.2985339 ],\n",
        "       [ 37794.52532364],\n",
        "       [  6949.26002361],\n",
        "       [  5195.24778149],\n",
        "       [  3510.06425946],\n",
        "       [  2179.78818952],\n",
        "       [  1385.7960766 ],\n",
        "       [ 11534.77415212],\n",
        "       [ 12426.21191639],\n",
        "       [ 14570.52442261],\n",
        "       [ 23987.76874976],\n",
        "       [ 19616.06321446],\n",
        "       [ 19970.38598875],\n",
        "       [  3789.33438728],\n",
        "       [  1386.13668337],\n",
        "       [  2801.36957988],\n",
        "       [  4358.93826166],\n",
        "       [ 19564.32297182],\n",
        "       [ 22553.67189286],\n",
        "       [  6853.33525793],\n",
        "       [  6837.8633967 ],\n",
        "       [  1925.52227487],\n",
        "       [  1133.48431202]])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately, we want a feature matrix and a target vector to shove into whatever machine learning code we want to use.\n",
      "Should be pretty easy to get that out of the above data structure though.\n",
      "Requirements of this code:\n",
      "\n",
      "* __Input__: subject, features, data\n",
      "* __Output___: X feature matrix, y target vector\n",
      "\n",
      "Prototyping this function in this notebook, then will save to `utils.py`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def buildtraining(subject,features,data):\n",
      "    \"\"\"Function to build data structures for ML:\n",
      "    \n",
      "    * __Input__: subject, features\n",
      "    * __Output___: X feature matrix, y target vector\n",
      "    \n",
      "    It will not tell you which feature is which.\"\"\"\n",
      "    # hacking this for later\n",
      "    first = features[0]\n",
      "    for feature in features:\n",
      "        Xf = np.array([])\n",
      "        # enumerate to get numbers for target vector:\n",
      "        #     0 is interictal\n",
      "        #     1 is preictal\n",
      "        for i,ictal in enumerate(['interictal','preictal']):\n",
      "            for segment in data[feature][subject][ictal].keys():\n",
      "                # now stack up the feature vectors\n",
      "                try:\n",
      "                    Xf = np.vstack([Xf,data[feature][subject][ictal][segment].T])\n",
      "                except ValueError:\n",
      "                    Xf = data[feature][subject][ictal][segment].T\n",
      "                # and stack up the target vector\n",
      "                # but only for the first feature (will be the same for the rest)\n",
      "                if feature == first:\n",
      "                    try:\n",
      "                        y.append(i)\n",
      "                    except NameError:\n",
      "                        y = [i]\n",
      "        # stick the X arrays together\n",
      "        try:\n",
      "            X = np.hstack([X,Xf])\n",
      "        except NameError:\n",
      "            X = Xf\n",
      "        except ValueError:\n",
      "            print(feature)\n",
      "            print(X.shape,Xf.shape)\n",
      "    # turn y into an array\n",
      "    y = np.array(y)\n",
      "    return X,y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How the enumerate works:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i,x in enumerate(['interictal','preictal']):\n",
      "    print(i,x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 interictal\n",
        "1 preictal\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Testing the above:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,y = buildtraining('Dog_1',['raw_feat_var_','raw_feat_cov_'],data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "(504, 136)"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "(504,)"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Appears to have worked.\n",
      "\n",
      "Attempting on all features."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,y = buildtraining('Dog_1',list(data.keys()),data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "raw_feat_pib_\n",
        "(504, 16) (504, 16, 6)\n",
        "raw_feat_xcorr_\n",
        "(504, 256) (504, 120, 2)\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Caught the above errors, looks like those two features are a bit weird.\n",
      "Maybe they're not coming in as vectors?\n",
      "\n",
      "Should probably just flatten them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def buildtraining(subject,features,data):\n",
      "    \"\"\"Function to build data structures for ML:\n",
      "    \n",
      "    * __Input__: subject, features\n",
      "    * __Output___: X feature matrix, y target vector\n",
      "    \n",
      "    It will not tell you which feature is which.\"\"\"\n",
      "    # hacking this for later\n",
      "    first = features[0]\n",
      "    for feature in features:\n",
      "        Xf = np.array([])\n",
      "        # enumerate to get numbers for target vector:\n",
      "        #     0 is interictal\n",
      "        #     1 is preictal\n",
      "        for i,ictal in enumerate(['interictal','preictal']):\n",
      "            for segment in data[feature][subject][ictal].keys():\n",
      "                # now stack up the feature vectors\n",
      "                try:\n",
      "                    Xf = np.vstack([Xf,np.ndarray.flatten(data[feature][subject][ictal][segment].T)])\n",
      "                except ValueError:\n",
      "                    Xf = np.ndarray.flatten(data[feature][subject][ictal][segment].T)\n",
      "                # and stack up the target vector\n",
      "                # but only for the first feature (will be the same for the rest)\n",
      "                if feature == first:\n",
      "                    try:\n",
      "                        y.append(i)\n",
      "                    except NameError:\n",
      "                        y = [i]\n",
      "        # stick the X arrays together\n",
      "        try:\n",
      "            X = np.hstack([X,Xf])\n",
      "        except NameError:\n",
      "            X = Xf\n",
      "        except ValueError:\n",
      "            print(feature)\n",
      "            print(X.shape,Xf.shape)\n",
      "    # turn y into an array\n",
      "    y = np.array(y)\n",
      "    return X,y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,y = buildtraining('Dog_1',list(data.keys()),data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, now appears to work."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%save buildtraining.py 56"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The following commands were written to file `buildtraining.py`:\n",
        "def buildtraining(subject,features,data):\n",
        "    \"\"\"Function to build data structures for ML:\n",
        "    \n",
        "    * __Input__: subject, features\n",
        "    * __Output___: X feature matrix, y target vector\n",
        "    \n",
        "    It will not tell you which feature is which.\"\"\"\n",
        "    # hacking this for later\n",
        "    first = features[0]\n",
        "    for feature in features:\n",
        "        Xf = np.array([])\n",
        "        # enumerate to get numbers for target vector:\n",
        "        #     0 is interictal\n",
        "        #     1 is preictal\n",
        "        for i,ictal in enumerate(['interictal','preictal']):\n",
        "            for segment in data[feature][subject][ictal].keys():\n",
        "                # now stack up the feature vectors\n",
        "                try:\n",
        "                    Xf = np.vstack([Xf,np.ndarray.flatten(data[feature][subject][ictal][segment].T)])\n",
        "                except ValueError:\n",
        "                    Xf = np.ndarray.flatten(data[feature][subject][ictal][segment].T)\n",
        "                # and stack up the target vector\n",
        "                # but only for the first feature (will be the same for the rest)\n",
        "                if feature == first:\n",
        "                    try:\n",
        "                        y.append(i)\n",
        "                    except NameError:\n",
        "                        y = [i]\n",
        "        # stick the X arrays together\n",
        "        try:\n",
        "            X = np.hstack([X,Xf])\n",
        "        except NameError:\n",
        "            X = Xf\n",
        "        except ValueError:\n",
        "            print(feature)\n",
        "            print(X.shape,Xf.shape)\n",
        "    # turn y into an array\n",
        "    y = np.array(y)\n",
        "    return X,y\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Learning\n",
      "\n",
      "Now we can actually do all the machine learning we need to do to make a submission. Not even bothering with feature selection, just going to build a pipeline and run K-fold cross validation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.preprocessing\n",
      "import sklearn.pipeline\n",
      "import sklearn.ensemble\n",
      "import sklearn.cross_validation\n",
      "import sklearn.svm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaler = sklearn.preprocessing.StandardScaler()\n",
      "forest = sklearn.ensemble.RandomForestClassifier()\n",
      "model = sklearn.pipeline.Pipeline([('scl',scaler),('clf',forest)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = sklearn.svm.SVC()\n",
      "modelsvc = sklearn.pipeline.Pipeline([('scl',scaler),('clf',svc)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Starting with default settings:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tenfold = sklearn.cross_validation.StratifiedKFold(y,n_folds=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 15
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.cross_validation.cross_val_score(model,X,y,cv=tenfold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([ 0.94117647,  0.94117647,  0.94117647,  0.94117647,  0.96      ,\n",
        "        0.96      ,  0.96      ,  0.96      ,  0.96      ,  0.96      ])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 17,
       "text": [
        "(504, 62080)"
       ]
      }
     ],
     "prompt_number": 17
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not that impressive, when you look at the all zeros for this one."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1-sum(y)/len(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "0.95238095238095233"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Trying increasing the number of trees we're using."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.set_params(clf__n_estimators=3000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=3000, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0))])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "sklearn.cross_validation.cross_val_score(model,X,y,cv=tenfold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 0 ns, sys: 0 ns, total: 0 ns\n",
        "Wall time: 13.8 \u00b5s\n"
       ]
      },
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 19,
       "text": [
        "array([ 0.94117647,  0.94117647,  0.94117647,  0.94117647,  0.96      ,\n",
        "        0.96      ,  0.96      ,  0.96      ,  0.96      ,  0.96      ])"
       ]
      }
     ],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.cross_validation.cross_val_score(modelsvc,X,y,cv=tenfold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 165,
       "text": [
        "array([ 0.94117647,  0.94117647,  0.94117647,  0.94117647,  0.96      ,\n",
        "        0.96      ,  0.96      ,  0.96      ,  0.96      ,  0.96      ])"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "sklearn.cross_validation.cross_val_score(model,X,y,cv=tenfold,scoring='roc_auc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 94,
       "text": [
        "array([ 0.94444444,  0.72569444,  0.77777778,  0.95833333,  0.9375    ,\n",
        "        1.        ,  0.84375   ,  0.76041667,  0.546875  ,  0.875     ])"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.cross_validation.cross_val_score(modelsvc,X,y,cv=tenfold,scoring='roc_auc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 166,
       "text": [
        "array([ 0.86111111,  0.92361111,  0.93055556,  0.86111111,  0.85416667,\n",
        "        0.89583333,  0.88541667,  0.84375   ,  0.92708333,  0.96875   ])"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Well, that's not below 0.5, so that's good enough for a submission.\n",
      "Time to go ahead and do that.\n",
      "\n",
      "So, I'll need another function like the one above to create a test matrix for each subject.\n",
      "Then, I can iterate over subjects, training the model and then classifying the test."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def buildtest(subject,features,data):\n",
      "    \"\"\"Function to build data structures for submission:\n",
      "    \n",
      "    * __Input__: subject, features, data\n",
      "    * __Output___: X feature matrix, labels\n",
      "    \n",
      "    It will not tell you which feature is which.\"\"\"\n",
      "    Xd = {}\n",
      "    for feature in features:\n",
      "        for segment in data[feature][subject]['test'].keys():\n",
      "            fvector = np.ndarray.flatten(data[feature][subject]['test'][segment])\n",
      "            try: \n",
      "                Xd[segment] = np.hstack([Xd[segment],fvector])\n",
      "            except:\n",
      "                Xd[segment] = fvector\n",
      "    # make the X array and corresponding labels\n",
      "    segments = []\n",
      "    X = []\n",
      "    for segment in Xd.keys():\n",
      "        segments.append(segment)\n",
      "        X.append(Xd[segment])\n",
      "    X = np.vstack(X)\n",
      "    return X,segments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 20
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = list(data.keys())\n",
      "subjects = list(data[features[0]].keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Had to remove this feature as it didn't cover all subjects for some reason."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features.remove('raw_feat_xcorr_')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 22
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,segments = buildtest(subjects[0],features,data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 24
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Works, but not saving as I want to reorganise the code I already saved as well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.set_params(clf__n_estimators=3000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 18,
       "text": [
        "Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=3000, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0))])"
       ]
      }
     ],
     "prompt_number": 18
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "predictiondict = {}\n",
      "for subj in subjects:\n",
      "    # training step\n",
      "    X,y = buildtraining(subj,features,data)\n",
      "    model.fit(X,y)\n",
      "    # prediction step\n",
      "    X,segments = buildtest(subj,features,data)\n",
      "    predictions = model.predict_proba(X)\n",
      "    for segment,prediction in zip(segments,predictions):\n",
      "        predictiondict[segment] = prediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 34min 38s, sys: 40.2 s, total: 35min 19s\n",
        "Wall time: 37min 48s\n"
       ]
      }
     ],
     "prompt_number": 26
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Running for SVC as well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "svcpredictiondict = {}\n",
      "for subj in subjects:\n",
      "    # training step\n",
      "    X,y = buildtraining(subj,features,data)\n",
      "    modelsvc.fit(X,y)\n",
      "    # prediction step\n",
      "    X,segments = buildtest(subj,features,data)\n",
      "    predictions = modelsvc.predict(X)\n",
      "    for segment,prediction in zip(segments,predictions):\n",
      "        svcpredictiondict[segment] = prediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1.03 s, sys: 3.33 ms, total: 1.04 s\n",
        "Wall time: 1.04 s\n"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Trying Logistic regression as we now have many more features."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.linear_model"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "logreg = sklearn.linear_model.LogisticRegression()\n",
      "modellr = sklearn.pipeline.Pipeline([('scl',scaler),('clf',logreg)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "lrpredictiondict = {}\n",
      "for subj in subjects:\n",
      "    # training step\n",
      "    X,y = buildtraining(subj,features,data)\n",
      "    modellr.fit(X,y)\n",
      "    # prediction step\n",
      "    X,segments = buildtest(subj,features,data)\n",
      "    predictions = modellr.predict_proba(X)\n",
      "    for segment,prediction in zip(segments,predictions):\n",
      "        lrpredictiondict[segment] = prediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 8min 12s, sys: 50.8 s, total: 9min 3s\n",
        "Wall time: 12min 13s\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Saving results to csv\n",
      "\n",
      "Have to save these results to the csv form requested:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 27
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"output/protosubmission.csv\",\"w\") as f:\n",
      "    c = csv.writer(f)\n",
      "    c.writerow(['clip','preictal'])\n",
      "    for seg in predictiondict.keys():\n",
      "        c.writerow([seg,\"%s\"%predictiondict[seg][-1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 30
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head output/protosubmission.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clip,preictal\r",
        "\r\n",
        "Dog_4_test_segment_0047.mat,0.608333333333\r",
        "\r\n",
        "Dog_4_test_segment_0369.mat,0.605666666667\r",
        "\r\n",
        "Dog_1_test_segment_0264.mat,0.598333333333\r",
        "\r\n",
        "Dog_2_test_segment_0925.mat,0.468333333333\r",
        "\r\n",
        "Dog_2_test_segment_0484.mat,0.475333333333\r",
        "\r\n",
        "Dog_1_test_segment_0267.mat,0.624333333333\r",
        "\r\n",
        "Dog_4_test_segment_0208.mat,0.601333333333\r",
        "\r\n",
        "Patient_1_test_segment_0089.mat,0.404\r",
        "\r\n",
        "Dog_2_test_segment_0131.mat,0.465333333333\r",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 31
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc -l output/protosubmission.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3936 output/protosubmission.csv\r\n"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks like it's the right length. Submitted now and we got 0.59308 for it, which isn't too bad.\n",
      "\n",
      "Saving LR as well:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"output/protolr.csv\",\"w\") as f:\n",
      "    c = csv.writer(f)\n",
      "    c.writerow(['clip','preictal'])\n",
      "    for seg in predictiondict.keys():\n",
      "        c.writerow([seg,\"%s\"%lrpredictiondict[seg][-1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head output/protosvc.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clip,preictal\r",
        "\r\n",
        "Dog_1_test_segment_0311.mat,0\r",
        "\r\n",
        "Dog_4_test_segment_0062.mat,0\r",
        "\r\n",
        "Dog_3_test_segment_0752.mat,0\r",
        "\r\n",
        "Dog_2_test_segment_0264.mat,0\r",
        "\r\n",
        "Dog_4_test_segment_0211.mat,0\r",
        "\r\n",
        "Dog_1_test_segment_0257.mat,0\r",
        "\r\n",
        "Dog_3_test_segment_0299.mat,0\r",
        "\r\n",
        "Dog_2_test_segment_0427.mat,0\r",
        "\r\n",
        "Dog_3_test_segment_0373.mat,0\r",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 170
    }
   ],
   "metadata": {}
  }
 ]
}