{
 "metadata": {
  "name": "",
  "signature": "sha256:cc1f403f7e9d36dd47746bc7f132501f7588a136808bb48e026d39ad7bf4f939"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%matplotlib inline\n",
      "plt.rcParams['figure.figsize'] = 6, 4.5\n",
      "plt.rcParams['axes.grid'] = True\n",
      "plt.gray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x7fc1f688d710>"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The aim of this notebook is to make a submission for this competition as quickly as possible.\n",
      "Just want to get something in.\n",
      "\n",
      "# Loading the data\n",
      "\n",
      "Getting all the filenames for Dog_1 ready, going to do the analysis on this first, then iterate over the rest after that."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd .."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/repositories/hail-seizure\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import train\n",
      "import json\n",
      "import imp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imp.reload(train)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 5,
       "text": [
        "<module 'train' from '/home/gavin/repositories/hail-seizure/train.py'>"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "First, have to load the settings from the json file:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "settings = json.load(open('SETTINGS.json', 'r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "settings.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 7,
       "text": [
        "dict_keys(['SUBMISSION_PATH', 'TRAIN_DATA_PATH', '_FEATURES', 'MODEL_PATH', 'VERSION', 'FEATURES', 'RAW_DATA_DIRS', 'SUBJECTS', 'TEST_DATA_PATH'])"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = train.get_data(settings['FEATURES'])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Doing this we get a dictionary of dictionarys:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "type(data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 10,
       "text": [
        "dict"
       ]
      }
     ],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data.keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 11,
       "text": [
        "dict_keys(['raw_feat_var_', 'raw_feat_pib_', 'raw_feat_corrcoef_', 'raw_feat_cov_', 'raw_feat_xcorr_'])"
       ]
      }
     ],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['raw_feat_var_'].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 12,
       "text": [
        "dict_keys(['Patient_2', 'Dog_3', 'Patient_1', 'Dog_1', 'Dog_4', 'Dog_2', 'Dog_5'])"
       ]
      }
     ],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['raw_feat_var_']['Patient_2'].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 13,
       "text": [
        "dict_keys(['interictal', 'preictal', 'test'])"
       ]
      }
     ],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['raw_feat_var_']['Patient_2']['interictal'].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 14,
       "text": [
        "dict_keys(['Patient_2_interictal_segment_0034.mat', 'Patient_2_interictal_segment_0013.mat', 'Patient_2_interictal_segment_0016.mat', 'Patient_2_interictal_segment_0040.mat', 'Patient_2_interictal_segment_0007.mat', 'Patient_2_interictal_segment_0039.mat', 'Patient_2_interictal_segment_0012.mat', 'Patient_2_interictal_segment_0033.mat', 'Patient_2_interictal_segment_0035.mat', 'Patient_2_interictal_segment_0006.mat', 'Patient_2_interictal_segment_0020.mat', 'Patient_2_interictal_segment_0015.mat', 'Patient_2_interictal_segment_0028.mat', 'Patient_2_interictal_segment_0003.mat', 'Patient_2_interictal_segment_0008.mat', 'Patient_2_interictal_segment_0014.mat', 'Patient_2_interictal_segment_0002.mat', 'Patient_2_interictal_segment_0022.mat', 'Patient_2_interictal_segment_0005.mat', 'Patient_2_interictal_segment_0029.mat', 'Patient_2_interictal_segment_0032.mat', 'Patient_2_interictal_segment_0025.mat', 'Patient_2_interictal_segment_0037.mat', 'Patient_2_interictal_segment_0036.mat', 'Patient_2_interictal_segment_0009.mat', 'Patient_2_interictal_segment_0019.mat', 'Patient_2_interictal_segment_0041.mat', 'Patient_2_interictal_segment_0011.mat', 'Patient_2_interictal_segment_0027.mat', 'Patient_2_interictal_segment_0023.mat', 'Patient_2_interictal_segment_0010.mat', 'Patient_2_interictal_segment_0042.mat', 'Patient_2_interictal_segment_0004.mat', 'Patient_2_interictal_segment_0030.mat', 'Patient_2_interictal_segment_0018.mat', 'Patient_2_interictal_segment_0026.mat', 'Patient_2_interictal_segment_0038.mat', 'Patient_2_interictal_segment_0001.mat', 'Patient_2_interictal_segment_0021.mat', 'Patient_2_interictal_segment_0031.mat', 'Patient_2_interictal_segment_0024.mat', 'Patient_2_interictal_segment_0017.mat'])"
       ]
      }
     ],
     "prompt_number": 14
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "It's dictionaries __all the way down__.\n",
      "\n",
      "Until you get to the feature vectors, obviously:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data['raw_feat_var_']['Patient_2']['interictal']['Patient_2_interictal_segment_0034.mat']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 16,
       "text": [
        "array([[ 27997.01668904],\n",
        "       [ 35989.2985339 ],\n",
        "       [ 37794.52532364],\n",
        "       [  6949.26002361],\n",
        "       [  5195.24778149],\n",
        "       [  3510.06425946],\n",
        "       [  2179.78818952],\n",
        "       [  1385.7960766 ],\n",
        "       [ 11534.77415212],\n",
        "       [ 12426.21191639],\n",
        "       [ 14570.52442261],\n",
        "       [ 23987.76874976],\n",
        "       [ 19616.06321446],\n",
        "       [ 19970.38598875],\n",
        "       [  3789.33438728],\n",
        "       [  1386.13668337],\n",
        "       [  2801.36957988],\n",
        "       [  4358.93826166],\n",
        "       [ 19564.32297182],\n",
        "       [ 22553.67189286],\n",
        "       [  6853.33525793],\n",
        "       [  6837.8633967 ],\n",
        "       [  1925.52227487],\n",
        "       [  1133.48431202]])"
       ]
      }
     ],
     "prompt_number": 16
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Unfortunately, we want a feature matrix and a target vector to shove into whatever machine learning code we want to use.\n",
      "Should be pretty easy to get that out of the above data structure though.\n",
      "Requirements of this code:\n",
      "\n",
      "* __Input__: subject, features, data\n",
      "* __Output___: X feature matrix, y target vector\n",
      "\n",
      "Prototyping this function in this notebook, then will save to `utils.py`."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 19
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def buildtraining(subject,features,data):\n",
      "    \"\"\"Function to build data structures for ML:\n",
      "    \n",
      "    * __Input__: subject, features\n",
      "    * __Output___: X feature matrix, y target vector\n",
      "    \n",
      "    It will not tell you which feature is which.\"\"\"\n",
      "    # hacking this for later\n",
      "    first = features[0]\n",
      "    for feature in features:\n",
      "        Xf = np.array([])\n",
      "        # enumerate to get numbers for target vector:\n",
      "        #     0 is interictal\n",
      "        #     1 is preictal\n",
      "        for i,ictal in enumerate(['interictal','preictal']):\n",
      "            for segment in data[feature][subject][ictal].keys():\n",
      "                # now stack up the feature vectors\n",
      "                try:\n",
      "                    Xf = np.vstack([Xf,data[feature][subject][ictal][segment].T])\n",
      "                except ValueError:\n",
      "                    Xf = data[feature][subject][ictal][segment].T\n",
      "                # and stack up the target vector\n",
      "                # but only for the first feature (will be the same for the rest)\n",
      "                if feature == first:\n",
      "                    try:\n",
      "                        y.append(i)\n",
      "                    except NameError:\n",
      "                        y = [i]\n",
      "        # stick the X arrays together\n",
      "        try:\n",
      "            X = np.hstack([X,Xf])\n",
      "        except NameError:\n",
      "            X = Xf\n",
      "        except ValueError:\n",
      "            print(feature)\n",
      "            print(X.shape,Xf.shape)\n",
      "    # turn y into an array\n",
      "    y = np.array(y)\n",
      "    return X,y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 51
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "How the enumerate works:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for i,x in enumerate(['interictal','preictal']):\n",
      "    print(i,x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0 interictal\n",
        "1 preictal\n"
       ]
      }
     ],
     "prompt_number": 21
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Testing the above:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,y = buildtraining('Dog_1',['raw_feat_var_','raw_feat_cov_'],data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 43,
       "text": [
        "(504, 136)"
       ]
      }
     ],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "(504,)"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Appears to have worked.\n",
      "\n",
      "Attempting on all features."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,y = buildtraining('Dog_1',list(data.keys()),data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "raw_feat_pib_\n",
        "(504, 16) (504, 16, 6)\n",
        "raw_feat_xcorr_\n",
        "(504, 256) (504, 120, 2)\n"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Caught the above errors, looks like those two features are a bit weird.\n",
      "Maybe they're not coming in as vectors?\n",
      "\n",
      "Should probably just flatten them."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def buildtraining(subject,features,data):\n",
      "    \"\"\"Function to build data structures for ML:\n",
      "    \n",
      "    * __Input__: subject, features\n",
      "    * __Output___: X feature matrix, y target vector\n",
      "    \n",
      "    It will not tell you which feature is which.\"\"\"\n",
      "    # hacking this for later\n",
      "    first = features[0]\n",
      "    for feature in features:\n",
      "        Xf = np.array([])\n",
      "        # enumerate to get numbers for target vector:\n",
      "        #     0 is interictal\n",
      "        #     1 is preictal\n",
      "        for i,ictal in enumerate(['interictal','preictal']):\n",
      "            for segment in data[feature][subject][ictal].keys():\n",
      "                # now stack up the feature vectors\n",
      "                try:\n",
      "                    Xf = np.vstack([Xf,np.ndarray.flatten(data[feature][subject][ictal][segment].T)])\n",
      "                except ValueError:\n",
      "                    Xf = np.ndarray.flatten(data[feature][subject][ictal][segment].T)\n",
      "                # and stack up the target vector\n",
      "                # but only for the first feature (will be the same for the rest)\n",
      "                if feature == first:\n",
      "                    try:\n",
      "                        y.append(i)\n",
      "                    except NameError:\n",
      "                        y = [i]\n",
      "        # stick the X arrays together\n",
      "        try:\n",
      "            X = np.hstack([X,Xf])\n",
      "        except NameError:\n",
      "            X = Xf\n",
      "        except ValueError:\n",
      "            print(feature)\n",
      "            print(X.shape,Xf.shape)\n",
      "    # turn y into an array\n",
      "    y = np.array(y)\n",
      "    return X,y"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 56
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,y = buildtraining('Dog_1',list(data.keys()),data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 162
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, now appears to work."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%save buildtraining.py 56"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "The following commands were written to file `buildtraining.py`:\n",
        "def buildtraining(subject,features,data):\n",
        "    \"\"\"Function to build data structures for ML:\n",
        "    \n",
        "    * __Input__: subject, features\n",
        "    * __Output___: X feature matrix, y target vector\n",
        "    \n",
        "    It will not tell you which feature is which.\"\"\"\n",
        "    # hacking this for later\n",
        "    first = features[0]\n",
        "    for feature in features:\n",
        "        Xf = np.array([])\n",
        "        # enumerate to get numbers for target vector:\n",
        "        #     0 is interictal\n",
        "        #     1 is preictal\n",
        "        for i,ictal in enumerate(['interictal','preictal']):\n",
        "            for segment in data[feature][subject][ictal].keys():\n",
        "                # now stack up the feature vectors\n",
        "                try:\n",
        "                    Xf = np.vstack([Xf,np.ndarray.flatten(data[feature][subject][ictal][segment].T)])\n",
        "                except ValueError:\n",
        "                    Xf = np.ndarray.flatten(data[feature][subject][ictal][segment].T)\n",
        "                # and stack up the target vector\n",
        "                # but only for the first feature (will be the same for the rest)\n",
        "                if feature == first:\n",
        "                    try:\n",
        "                        y.append(i)\n",
        "                    except NameError:\n",
        "                        y = [i]\n",
        "        # stick the X arrays together\n",
        "        try:\n",
        "            X = np.hstack([X,Xf])\n",
        "        except NameError:\n",
        "            X = Xf\n",
        "        except ValueError:\n",
        "            print(feature)\n",
        "            print(X.shape,Xf.shape)\n",
        "    # turn y into an array\n",
        "    y = np.array(y)\n",
        "    return X,y\n"
       ]
      }
     ],
     "prompt_number": 82
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Learning\n",
      "\n",
      "Now we can actually do all the machine learning we need to do to make a submission. Not even bothering with feature selection, just going to build a pipeline and run K-fold cross validation."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.preprocessing\n",
      "import sklearn.pipeline\n",
      "import sklearn.ensemble\n",
      "import sklearn.cross_validation\n",
      "import sklearn.svm"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 156
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaler = sklearn.preprocessing.StandardScaler()\n",
      "forest = sklearn.ensemble.RandomForestClassifier()\n",
      "model = sklearn.pipeline.Pipeline([('scl',scaler),('clf',forest)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 64
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "svc = sklearn.svm.SVC()\n",
      "modelsvc = sklearn.pipeline.Pipeline([('scl',scaler),('clf',svc)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 157
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Starting with default settings:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "tenfold = sklearn.cross_validation.StratifiedKFold(y,n_folds=10)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 164
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.cross_validation.cross_val_score(model,X,y,cv=tenfold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 77,
       "text": [
        "array([ 0.94117647,  0.94117647,  0.96078431,  0.94117647,  0.96      ,\n",
        "        0.96      ,  0.96      ,  0.96      ,  0.96      ,  0.96      ])"
       ]
      }
     ],
     "prompt_number": 77
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Not that impressive, when you look at the all zeros for this one."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "1-sum(y)/len(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 80,
       "text": [
        "0.95238095238095233"
       ]
      }
     ],
     "prompt_number": 80
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Trying increasing the number of trees we're using."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.set_params(clf__n_estimators=3000)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 87,
       "text": [
        "Pipeline(steps=[('scl', StandardScaler(copy=True, with_mean=True, with_std=True)), ('clf', RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=3000, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0))])"
       ]
      }
     ],
     "prompt_number": 87
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.cross_validation.cross_val_score(model,X,y,cv=tenfold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 92,
       "text": [
        "array([ 0.94117647,  0.94117647,  0.94117647,  0.94117647,  0.96      ,\n",
        "        0.96      ,  0.96      ,  0.96      ,  0.96      ,  0.96      ])"
       ]
      }
     ],
     "prompt_number": 92
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.cross_validation.cross_val_score(modelsvc,X,y,cv=tenfold)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 165,
       "text": [
        "array([ 0.94117647,  0.94117647,  0.94117647,  0.94117647,  0.96      ,\n",
        "        0.96      ,  0.96      ,  0.96      ,  0.96      ,  0.96      ])"
       ]
      }
     ],
     "prompt_number": 165
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.cross_validation.cross_val_score(model,X,y,cv=tenfold,scoring='roc_auc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 94,
       "text": [
        "array([ 0.94444444,  0.72569444,  0.77777778,  0.95833333,  0.9375    ,\n",
        "        1.        ,  0.84375   ,  0.76041667,  0.546875  ,  0.875     ])"
       ]
      }
     ],
     "prompt_number": 94
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sklearn.cross_validation.cross_val_score(modelsvc,X,y,cv=tenfold,scoring='roc_auc')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 166,
       "text": [
        "array([ 0.86111111,  0.92361111,  0.93055556,  0.86111111,  0.85416667,\n",
        "        0.89583333,  0.88541667,  0.84375   ,  0.92708333,  0.96875   ])"
       ]
      }
     ],
     "prompt_number": 166
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Well, that's not below 0.5, so that's good enough for a submission.\n",
      "Time to go ahead and do that.\n",
      "\n",
      "So, I'll need another function like the one above to create a test matrix for each subject.\n",
      "Then, I can iterate over subjects, training the model and then classifying the test."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "def buildtest(subject,features,data):\n",
      "    \"\"\"Function to build data structures for submission:\n",
      "    \n",
      "    * __Input__: subject, features, data\n",
      "    * __Output___: X feature matrix, labels\n",
      "    \n",
      "    It will not tell you which feature is which.\"\"\"\n",
      "    Xd = {}\n",
      "    for feature in features:\n",
      "        for segment in data[feature][subject]['test'].keys():\n",
      "            fvector = np.ndarray.flatten(data[feature][subject]['test'][segment])\n",
      "            try: \n",
      "                Xd[segment] = np.hstack([Xd[segment],fvector])\n",
      "            except:\n",
      "                Xd[segment] = fvector\n",
      "    # make the X array and corresponding labels\n",
      "    segments = []\n",
      "    X = []\n",
      "    for segment in Xd.keys():\n",
      "        segments.append(segment)\n",
      "        X.append(Xd[segment])\n",
      "    X = np.vstack(X)\n",
      "    return X,segments"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 139
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = list(data.keys())\n",
      "subjects = list(data[features[0]].keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 102
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Had to remove this feature as it didn't cover all subjects for some reason."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features.remove('raw_feat_xcorr_')"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 117
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X,segments = buildtest(subjects[0],features,data)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 140
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(segments)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 141,
       "text": [
        "150"
       ]
      }
     ],
     "prompt_number": 141
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X.shape"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 142,
       "text": [
        "(150, 720)"
       ]
      }
     ],
     "prompt_number": 142
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Works, but not saving as I want to reorganise the code I already saved as well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "predictiondict = {}\n",
      "for subj in subjects:\n",
      "    # training step\n",
      "    X,y = buildtraining(subj,features,data)\n",
      "    model.fit(X,y)\n",
      "    # prediction step\n",
      "    X,segments = buildtest(subj,features,data)\n",
      "    predictions = model.predict_proba(X)\n",
      "    for segment,prediction in zip(segments,predictions):\n",
      "        predictiondict[segment] = prediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1min 17s, sys: 13.3 ms, total: 1min 17s\n",
        "Wall time: 1min 17s\n"
       ]
      }
     ],
     "prompt_number": 147
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Running for SVC as well."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "svcpredictiondict = {}\n",
      "for subj in subjects:\n",
      "    # training step\n",
      "    X,y = buildtraining(subj,features,data)\n",
      "    modelsvc.fit(X,y)\n",
      "    # prediction step\n",
      "    X,segments = buildtest(subj,features,data)\n",
      "    predictions = modelsvc.predict(X)\n",
      "    for segment,prediction in zip(segments,predictions):\n",
      "        svcpredictiondict[segment] = prediction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "CPU times: user 1.03 s, sys: 3.33 ms, total: 1.04 s\n",
        "Wall time: 1.04 s\n"
       ]
      }
     ],
     "prompt_number": 167
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Saving results to csv\n",
      "\n",
      "Have to save these results to the csv form requested:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 149
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"output/protosubmission.csv\",\"w\") as f:\n",
      "    c = csv.writer(f)\n",
      "    c.writerow(['clip','preictal'])\n",
      "    for seg in predictiondict.keys():\n",
      "        c.writerow([seg,\"%s\"%predictiondict[seg]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 152
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head output/protosubmission.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clip,preictal\r",
        "\r\n",
        "Dog_1_test_segment_0311.mat,0\r",
        "\r\n",
        "Dog_4_test_segment_0062.mat,0\r",
        "\r\n",
        "Dog_3_test_segment_0752.mat,0\r",
        "\r\n",
        "Dog_2_test_segment_0264.mat,1\r",
        "\r\n",
        "Dog_4_test_segment_0211.mat,0\r",
        "\r\n",
        "Dog_1_test_segment_0257.mat,0\r",
        "\r\n",
        "Dog_3_test_segment_0299.mat,0\r",
        "\r\n",
        "Dog_2_test_segment_0427.mat,0\r",
        "\r\n",
        "Dog_3_test_segment_0373.mat,0\r",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 153
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc -l output/protosubmission.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3936 output/protosubmission.csv\r\n"
       ]
      }
     ],
     "prompt_number": 154
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks like it's the right length. Submitted now and we got 0.59308 for it, which isn't too bad.\n",
      "\n",
      "Saving SVC as well:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"output/protosvc.csv\",\"w\") as f:\n",
      "    c = csv.writer(f)\n",
      "    c.writerow(['clip','preictal'])\n",
      "    for seg in predictiondict.keys():\n",
      "        c.writerow([seg,\"%s\"%svcpredictiondict[seg]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 169
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head output/protosvc.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clip,preictal\r",
        "\r\n",
        "Dog_1_test_segment_0311.mat,0\r",
        "\r\n",
        "Dog_4_test_segment_0062.mat,0\r",
        "\r\n",
        "Dog_3_test_segment_0752.mat,0\r",
        "\r\n",
        "Dog_2_test_segment_0264.mat,0\r",
        "\r\n",
        "Dog_4_test_segment_0211.mat,0\r",
        "\r\n",
        "Dog_1_test_segment_0257.mat,0\r",
        "\r\n",
        "Dog_3_test_segment_0299.mat,0\r",
        "\r\n",
        "Dog_2_test_segment_0427.mat,0\r",
        "\r\n",
        "Dog_3_test_segment_0373.mat,0\r",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 170
    }
   ],
   "metadata": {}
  }
 ]
}