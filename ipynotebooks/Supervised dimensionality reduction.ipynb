{
 "metadata": {
  "name": "",
  "signature": "sha256:fad6258e709bed46b54a81445183d85b9ad446da9705e2e6d0c955f7a1c34bed"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The idea in this notebook is to reduce the dimensionality of the datasets by transforming individual features using classifiers.\n",
      "Once we've done this it will be possible to combine the subject specific datasets into a single global dataset.\n",
      "This might run the risk of overfitting, but it is also a nice way to create a global classifier.\n",
      "\n",
      "Loading the data and initialisation\n",
      "===================================\n",
      "\n",
      "Same initialisation steps as in other notebooks:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "%matplotlib inline\n",
      "plt.rcParams['figure.figsize'] = 6, 4.5\n",
      "plt.rcParams['axes.grid'] = True\n",
      "plt.gray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x7f3e64700470>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd .."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/repositories/hail-seizure\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import train\n",
      "import json\n",
      "import imp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "settings = json.load(open('SETTINGS.json', 'r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = train.get_data(settings['FEATURES'][:3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!free -m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             total       used       free     shared    buffers     cached\r\n",
        "Mem:         11933      11220        712        384        355       3429\r\n",
        "-/+ buffers/cache:       7435       4497\r\n",
        "Swap:        12287         34      12253\r\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Random forest supervised classification\n",
      "=======================================\n",
      "\n",
      "For each feature and each subject we want to train a random forest and use it to transform the data.\n",
      "We also want to appropriately weight the samples due to the unbalanced classes.\n",
      "\n",
      "Since I'm a big fan of dictionaries it seems like it would be easy to do this with a dictionary iterating over subjects and features and saving predictions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.preprocessing\n",
      "import sklearn.pipeline\n",
      "import sklearn.ensemble\n",
      "import sklearn.cross_validation\n",
      "from train import utils"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imp.reload(utils)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 9,
       "text": [
        "<module 'python.utils' from '/home/gavin/repositories/hail-seizure/python/utils.py'>"
       ]
      }
     ],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below code copied and modified from random forest submission notes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = settings['FEATURES'][:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 12
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subjects = settings['SUBJECTS']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaler = sklearn.preprocessing.StandardScaler()\n",
      "forest = sklearn.ensemble.RandomForestClassifier()\n",
      "model = sklearn.pipeline.Pipeline([('scl',scaler),('clf',forest)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 13
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "predictiondict = {}\n",
      "for feature in features:\n",
      "    print(\"Processing {0}\".format(feature))\n",
      "    for subj in subjects:\n",
      "        # training step\n",
      "        X,y,cv,segments = utils.build_training(subj,[feature],data)\n",
      "        for i, (train, test) in enumerate(cv):\n",
      "            weight = len(y[train])/sum(y[train])\n",
      "            weights = np.array([weight if i == 1 else 1 for i in y[train]])\n",
      "            model.fit(X[train],y[train],clf__sample_weight=weights)\n",
      "            predictions = model.predict_proba(X)\n",
      "            for name,split in [('train',train),('test',test)]:\n",
      "                for segment,prediction in zip(segments[split],predictions[split]):\n",
      "                    try:\n",
      "                        predictiondict[segment][feature] = {}\n",
      "                        predictiondict[segment][feature][i] = (name,prediction)\n",
      "                    except:\n",
      "                        predictiondict[segment] = {}\n",
      "                        predictiondict[segment][feature] = {}\n",
      "                        predictiondict[segment][feature][i] = (name,prediction)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing ica_feat_var_\n",
        "Processing ica_feat_cov_"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing ica_feat_corrcoef_"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CPU times: user 3 s, sys: 10 ms, total: 3.01 s"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wall time: 3.01 s\n"
       ]
      }
     ],
     "prompt_number": 36
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, creating the full training set for a single train/test iteration:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "segments = list(predictiondict.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 37
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictiondict[segments[0]].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 38,
       "text": [
        "dict_keys(['ica_feat_var_', 'ica_feat_cov_', 'ica_feat_corrcoef_'])"
       ]
      }
     ],
     "prompt_number": 38
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.array([])[np.newaxis]\n",
      "train,test = [],[]\n",
      "for i,segment in enumerate(segments):\n",
      "    row = []\n",
      "    for feature in features:\n",
      "        cv = list(predictiondict[segment][feature].keys())\n",
      "        row.append(predictiondict[segment][feature][cv[0]][-1][-1])\n",
      "        name = predictiondict[segment][feature][cv[0]][0]\n",
      "        if name == 'train':\n",
      "            train.append(i)\n",
      "        elif name == 'test':\n",
      "            test.append(i)\n",
      "        else:\n",
      "            print(\"segment {0} does not have a valid label: {1}\".format(i,name))\n",
      "    try:\n",
      "        X = np.vstack([X,np.array(row)[np.newaxis]])\n",
      "    except:\n",
      "        X = np.array(row)[np.newaxis]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 40
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 41,
       "text": [
        "array([[ 0. ,  0.1,  0. ],\n",
        "       [ 0. ,  0. ,  0. ],\n",
        "       [ 0.1,  0. ,  0. ],\n",
        "       ..., \n",
        "       [ 0. ,  0.1,  0.1],\n",
        "       [ 0. ,  0. ,  0. ],\n",
        "       [ 0. ,  0. ,  0. ]])"
       ]
      }
     ],
     "prompt_number": 41
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = [1 if 'preictal' in segment else 0 for segment in segments]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 42
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = np.array(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 43
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 44,
       "text": [
        "4067"
       ]
      }
     ],
     "prompt_number": 44
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 45,
       "text": [
        "4067"
       ]
      }
     ],
     "prompt_number": 45
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(segments)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 46,
       "text": [
        "4067"
       ]
      }
     ],
     "prompt_number": 46
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.fit(X[train],y[train])\n",
      "predictions = model.predict_proba(X[test])\n",
      "score = sklearn.metrics.roc_auc_score(y[test],predictions[:,1])\n",
      "print(score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.784804226469\n"
       ]
      }
     ],
     "prompt_number": 48
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "sum(predictions)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 52,
       "text": [
        "array([ 9684.86943723,   479.13056277])"
       ]
      }
     ],
     "prompt_number": 52
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Saving this operation as a script\n",
      "=================================\n",
      "\n",
      "We will probably want to be able to do this again, so we should save this operation as a function in `utils.py`.\n",
      "Will do this once it works."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}