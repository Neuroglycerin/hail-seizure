{
 "metadata": {
  "name": "",
  "signature": "sha256:eddc622ce536e0dc3bba73148fc007b4b5545fd54dd7afd0463a8a7cdf953c9a"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The idea in this notebook is to reduce the dimensionality of the datasets by transforming individual features using classifiers.\n",
      "Once we've done this it will be possible to combine the subject specific datasets into a single global dataset.\n",
      "This might run the risk of overfitting, but it is also a nice way to create a global classifier.\n",
      "\n",
      "Loading the data and initialisation\n",
      "===================================\n",
      "\n",
      "Same initialisation steps as in other notebooks:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "import numpy as np\n",
      "%matplotlib inline\n",
      "plt.rcParams['figure.figsize'] = 6, 4.5\n",
      "plt.rcParams['axes.grid'] = True\n",
      "plt.gray()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "display_data",
       "text": [
        "<matplotlib.figure.Figure at 0x7ff9dc955470>"
       ]
      }
     ],
     "prompt_number": 1
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cd .."
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "/home/gavin/repositories/hail-seizure\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import train\n",
      "import json\n",
      "import imp"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "settings = json.load(open('SETTINGS.json', 'r'))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "data = train.get_data(settings['FEATURES'][:3])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!free -m"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             total       used       free     shared    buffers     cached\r\n",
        "Mem:         11933       5066       6866        385        368       2533\r\n",
        "-/+ buffers/cache:       2164       9768\r\n",
        "Swap:        12287         41      12246\r\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Random forest supervised classification\n",
      "=======================================\n",
      "\n",
      "For each feature and each subject we want to train a random forest and use it to transform the data.\n",
      "We also want to appropriately weight the samples due to the unbalanced classes.\n",
      "\n",
      "Since I'm a big fan of dictionaries it seems like it would be easy to do this with a dictionary iterating over subjects and features and saving predictions."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.preprocessing\n",
      "import sklearn.pipeline\n",
      "import sklearn.ensemble\n",
      "import sklearn.cross_validation\n",
      "from train import utils"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 7
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "imp.reload(utils)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 8,
       "text": [
        "<module 'python.utils' from '/home/gavin/repositories/hail-seizure/python/utils.py'>"
       ]
      }
     ],
     "prompt_number": 8
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Below code copied and modified from random forest submission notes:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = settings['FEATURES'][:3]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 221
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "subjects = settings['SUBJECTS']"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 10
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "scaler = sklearn.preprocessing.StandardScaler()\n",
      "forest = sklearn.ensemble.RandomForestClassifier()\n",
      "model = sklearn.pipeline.Pipeline([('scl',scaler),('clf',forest)])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 11
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import sklearn.feature_extraction"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 166
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oneofk = sklearn.preprocessing.OneHotEncoder(sparse=False)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 179
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "x = np.arange(10)[np.newaxis]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 180
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "oneofk.fit_transform(x)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 181,
       "text": [
        "array([[ 1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.,  1.]])"
       ]
      }
     ],
     "prompt_number": 181
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "%%time\n",
      "predictiondict = {}\n",
      "for feature in features:\n",
      "    print(\"Processing {0}\".format(feature))\n",
      "    for i,subj in enumerate(subjects):\n",
      "        # training step\n",
      "        X,y,cv,segments = utils.build_training(subj,[feature],data)\n",
      "        X = scaler.fit_transform(X)\n",
      "        predictions = np.mean(X,axis=1)\n",
      "        for segment,prediction in zip(segments,predictions):\n",
      "            try:\n",
      "                predictiondict[segment][feature] = [prediction]\n",
      "            except:\n",
      "                predictiondict[segment] = {}\n",
      "                predictiondict[segment][feature] = [prediction]\n",
      "            # add subject 1-of-k vector\n",
      "            subjvector = np.zeros(len(subjects))\n",
      "            subjvector[i] = 1\n",
      "            predictiondict[segment]['subject'] = list(subjvector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing ica_feat_var_\n",
        "Processing ica_feat_cov_"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing ica_feat_corrcoef_"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "CPU times: user 847 ms, sys: 30 ms, total: 877 ms"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Wall time: 873 ms\n"
       ]
      }
     ],
     "prompt_number": 240
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Next, creating the full training set:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "segments = list(predictiondict.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 241
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictiondict[segments[0]].keys()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 242,
       "text": [
        "dict_keys(['ica_feat_cov_', 'ica_feat_var_', 'ica_feat_corrcoef_', 'subject'])"
       ]
      }
     ],
     "prompt_number": 242
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.array([])[np.newaxis]\n",
      "train,test = [],[]\n",
      "for i,segment in enumerate(segments):\n",
      "    row = []\n",
      "    for feature in features+['subject']:\n",
      "        row += predictiondict[segment][feature]\n",
      "    try:\n",
      "        X = np.vstack([X,np.array(row)[np.newaxis]])\n",
      "    except:\n",
      "        X = np.array(row)[np.newaxis]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 243
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 244,
       "text": [
        "array([[-0.49685521,  0.00605736,  0.01370309, ...,  0.        ,\n",
        "         0.        ,  0.        ],\n",
        "       [ 0.51705194,  0.04152316,  0.05378171, ...,  0.        ,\n",
        "         0.        ,  0.        ],\n",
        "       [-0.11685621,  0.04234982,  0.04947848, ...,  0.        ,\n",
        "         0.        ,  0.        ],\n",
        "       ..., \n",
        "       [-0.35475441, -0.02805797, -0.01568938, ...,  0.        ,\n",
        "         0.        ,  0.        ],\n",
        "       [-0.05627469,  0.0089621 ,  0.0347518 , ...,  0.        ,\n",
        "         0.        ,  0.        ],\n",
        "       [-0.19796733,  0.04504965,  0.06480923, ...,  0.        ,\n",
        "         0.        ,  0.        ]])"
       ]
      }
     ],
     "prompt_number": 244
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = [1 if 'preictal' in segment else 0 for segment in segments]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 245
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "y = np.array(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 246
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 247,
       "text": [
        "4067"
       ]
      }
     ],
     "prompt_number": 247
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(X)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 248,
       "text": [
        "4067"
       ]
      }
     ],
     "prompt_number": 248
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(segments)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 249,
       "text": [
        "4067"
       ]
      }
     ],
     "prompt_number": 249
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "cv = sklearn.cross_validation.StratifiedShuffleSplit(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 250
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weight = len(y)/sum(y)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 255
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "weights = [weight if i == 1 else 1 for i in y]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 256
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "for train,test in cv:\n",
      "    forest.fit(X[train],y[train],sample_weight=weight)\n",
      "    predictions = forest.predict_proba(X[test])\n",
      "    score = sklearn.metrics.roc_auc_score(y[test],predictions[:,1])\n",
      "    print(score)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "0.653801945181\n",
        "0.690848806366\n",
        "0.573430592396"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.679442970822\n",
        "0.703227232538"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.681520778073\n",
        "0.724845269673"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.661582670203\n",
        "0.772944297082"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "0.705702917772\n"
       ]
      }
     ],
     "prompt_number": 258
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "forest.fit(X,y,sample_weight=weights)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 261,
       "text": [
        "RandomForestClassifier(bootstrap=True, compute_importances=None,\n",
        "            criterion='gini', max_depth=None, max_features='auto',\n",
        "            max_leaf_nodes=None, min_density=None, min_samples_leaf=1,\n",
        "            min_samples_split=2, n_estimators=10, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0)"
       ]
      }
     ],
     "prompt_number": 261
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictiondict = {}\n",
      "for feature in features:\n",
      "    print(\"Processing {0}\".format(feature))\n",
      "    for i,subj in enumerate(subjects):\n",
      "        X,segments = utils.build_test(subj,[feature],data)\n",
      "        X = scaler.fit_transform(X)\n",
      "        predictions = np.mean(X,axis=1)\n",
      "        for segment,prediction in zip(segments,predictions):\n",
      "            try:\n",
      "                predictiondict[segment][feature] = [prediction]\n",
      "            except:\n",
      "                predictiondict[segment] = {}\n",
      "                predictiondict[segment][feature] = [prediction]\n",
      "            # add subject 1-of-k vector\n",
      "            subjvector = np.zeros(len(subjects))\n",
      "            subjvector[i] = 1\n",
      "            predictiondict[segment]['subject'] = list(subjvector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Processing ica_feat_var_\n",
        "Processing ica_feat_cov_"
       ]
      },
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "\n",
        "Processing ica_feat_corrcoef_\n"
       ]
      }
     ],
     "prompt_number": 264
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "segments = list(predictiondict.keys())"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 265
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "X = np.array([])[np.newaxis]\n",
      "for i,segment in enumerate(segments):\n",
      "    row = []\n",
      "    for feature in features+['subject']:\n",
      "        row += predictiondict[segment][feature]\n",
      "    try:\n",
      "        X = np.vstack([X,np.array(row)[np.newaxis]])\n",
      "    except:\n",
      "        X = np.array(row)[np.newaxis]"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 266
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 267
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "predictiondict = {}\n",
      "for segment,fvector in zip(segments,X):\n",
      "    predictiondict[segment] = forest.predict_proba(fvector)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 268
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "with open(\"output/protosubmission.csv\",\"w\") as f:\n",
      "    c = csv.writer(f)\n",
      "    c.writerow(['clip','preictal'])\n",
      "    for seg in predictiondict.keys():\n",
      "        c.writerow([seg,\"%s\"%predictiondict[seg][-1][-1]])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 269
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!head output/protosubmission.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "clip,preictal\r",
        "\r\n",
        "Dog_1_test_segment_0300.mat,0.1\r",
        "\r\n",
        "Dog_3_test_segment_0363.mat,0.0\r",
        "\r\n",
        "Dog_2_test_segment_0321.mat,0.0\r",
        "\r\n",
        "Dog_2_test_segment_0413.mat,0.1\r",
        "\r\n",
        "Dog_2_test_segment_0755.mat,0.0\r",
        "\r\n",
        "Dog_1_test_segment_0408.mat,0.0\r",
        "\r\n",
        "Dog_4_test_segment_0383.mat,0.1\r",
        "\r\n",
        "Dog_2_test_segment_0524.mat,0.2\r",
        "\r\n",
        "Patient_2_test_segment_0020.mat,0.5\r",
        "\r\n"
       ]
      }
     ],
     "prompt_number": 270
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc -l output/protosubmission.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3936 output/protosubmission.csv\r\n"
       ]
      }
     ],
     "prompt_number": 271
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "!wc -l output/sampleSubmission.csv"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "3935 output/sampleSubmission.csv\r\n"
       ]
      }
     ],
     "prompt_number": 272
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Wrong length, but I submitted it anyway and it got 0.53141.\n",
      "After adding 1-of-k encoded subjects and weightings got 0.56016.\n",
      "So, that should hold when I add more features, or do the above in a smarter way."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Saving this operation as a script\n",
      "=================================\n",
      "\n",
      "We will probably want to be able to do this again, so we should save this operation as a function in `utils.py`.\n",
      "Will do this once it works."
     ]
    }
   ],
   "metadata": {}
  }
 ]
}